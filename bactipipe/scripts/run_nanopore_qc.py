import nano_qc
import argparse
import sys
import os
import csv
import time
import socket
import psutil
from datetime import datetime
from bactipipe.scripts import process_data
from bactipipe.scripts import find_orgnanism
from tqdm.contrib.concurrent import process_map
from bactipipe.scripts.utils import time_print, simple_print, logger, pipeheader
from importlib.resources import files


class CustomHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):
    def __init__(self, *args, **kwargs):
        kwargs['width'] = 100  # Set the width of the help message
        super().__init__(*args, **kwargs)

    def _get_help_string(self, action):
        if action.default is not None and action.default != argparse.SUPPRESS:
            return super()._get_help_string(action)
        return action.help

parser = argparse.ArgumentParser(
    description="Perform quality control on nanopore reads, assemble genomes for reads that pass QC, and check quality for assembled genomes.",
    formatter_class=CustomHelpFormatter,
    add_help=False  # Disable default help to add it manually
)

required_args = parser.add_argument_group('Required arguments')
optional_args = parser.add_argument_group('Optional arguments')


required_args.add_argument("-n", "--name",
                    help='Name of the person running the pipeline. Needs quotations to handle spaces.\
                        Example: -n "Jane Doe"', required=True)

required_args.add_argument("-r", "--run_name",
                    help="Run name (Run ID)", required=True)

required_args.add_argument("-l", "--sample_sheet",
                    help="A three-column file with sample (column 1), organism species (column2), barcode(column3 -- [format: NBDXX or barcodeXX]).", required=True)

required_args.add_argument('-s', '--source', help='The source directory.', required=True)

optional_args.add_argument("-o", "--outdir",
                    help="Path to output directory. Default: current directory.")
optional_args.add_argument('-t', '--threads', help='Number of CPUs per sample. Default: all available.', type=int)


optional_args.add_argument("--cpus_per_sample", help="Number of CPUs per sample. Must be lower than total allocated CPUs. If not provided,  it will be calculated based on available resources.", type=int)

optional_args.add_argument("-m", "--mincov", help="Minimum genome coverage depth.", default=50, type=int)

optional_args.add_argument("-q", "--minqual", help="Average read quality threshold.", default=15, type=int)

optional_args.add_argument("--clean",
                            help="This will delete all fastq samples generated by QC step.",
                            action="store_true")

optional_args.add_argument("-h", "--help",
                           action="help",
                           help="Show this help message and exit.")

args = parser.parse_args()

# Function to run quality control for a single sample
def process_sample(line):
    sample, organism, barcode = line.strip().split('\t')
    barcode = barcode.replace("NB", "barcode")

    genome_size = 48502 if organism == "Lambda" else bacteria.get(organism, None)
    raw_folder = os.path.join(source, barcode)
    output_fastq = f"{sample}.fastq.gz"
    output_dir = os.path.join(qc_out, sample)
    qc_final_file = os.path.join(output_dir, "quality_metrics_after_qc.txt")
    if os.path.exists(qc_final_file):
        return

    # Run QC with controlled CPU allocation
    if sample != "sample_ID":
        nano_qc.qc_nano(
            raw_folder=raw_folder,
            genome_size=genome_size,
            min_avg_quality=15,
            min_coverage=50,
            desired_coverage=300,
            step_coverage=50,
            output_fastq=output_fastq,
            output_dir=output_dir,
            cpus=str(cpus_per_sample),
            single=False
        )

    # Clean up intermediate files
    for file in os.listdir(output_dir):
        file_path = os.path.join(output_dir, file)
        if "barcode" in file and "fastq.gz" in file:
            os.remove(file_path)
        elif "nanoplot_initial" in file or "nanoplot_last" in file:
            os.system(f"rm -r {file_path}")

# Function for genome assembly for one sample
def assemble_sample(assembly_input):
    sample = assembly_input[0]
    fastq = assembly_input[1]
    genome_size = 48502 if organism == "Lambda" else bacteria.get(organism, None)
    # Assemble the genomes of the samples that passed the quality control
    assembly_dir = os.path.join(outDir, "assemblies")
    genome = os.path.join(assembly_dir, "genomes", f"{sample}.fasta")
    if os.path.exists(genome):
        return
    process_data.assemble(sample=sample, reads=[fastq], assembly_dir=assembly_dir, sequencer="nanopore", cpus=cpus_per_sample, gsize = genome_size, single=False)
    return

# Run the pipeline
tech_name = args.name
run_name = args.run_name
source = args.source
source = os.path.join(source, run_name)
if args.outdir:
    outDir = os.path.join(args.outdir, run_name)
else:
    outDir = os.path.join(os.getcwd(), run_name)

mincov = args.mincov
minqual = args.minqual
sample_list = os.path.abspath(args.sample_sheet)


log_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
log = os.path.join(outDir, f"{log_time}~{run_name}_qc.log")

date = datetime.now().strftime("%Y-%m-%d")
hostname = socket.gethostname()
try:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        # doesn't even have to be reachable
        s.connect(('10.254.254.254', 1))
        ip_address = s.getsockname()[0]
    except Exception as e:
        time_print(f"Unable to resolve hostname: {e}", "Fail")
        ip_address = "Not detected"
    finally:
        s.close()
except Exception as e:
    ip_address = f"Unable to resolve hostname: {e}"
    ip_address = "Unable to resolve hostname"

# Manage computational resources
if args.threads:
    cpus = args.threads
else:
    cpus = os.cpu_count()


opt_cpus = max(1, cpus // 8)  # Optimal number of CPUs per sample
if opt_cpus == 1:
    defaut_max_samps = 1 # We can only run one sample at a time
else:
    defaut_max_samps = cpus // opt_cpus  # Maximum number of samples to process in parallel

# Calculate available memory
mem = psutil.virtual_memory()
a_mem = mem.available / 1024**3  # available memory in GB
t_mem = mem.total / 1024**3  # total memory in GB


allowed_samps = a_mem // 8  # 8 GB per sample

if allowed_samps < 1:
    time_print("Insufficient memory available to run the pipeline.", "Fail")
    sys.exit(1)

if allowed_samps < defaut_max_samps:
    pool_size = allowed_samps
else:
    pool_size = defaut_max_samps

if args.cpus_per_sample:
    cpus_per_sample = args.cpus_per_sample
else:
    cpus_per_sample = max(1, cpus // pool_size)

# Ensure that the source directory exists
if not os.path.exists(source):
    print(f"Source directory {source} does not exist.")
    logger(log, f"Source directory {source} does not exist.")
    sys.exit(1)

for root, dirs, files in os.walk(source):
    for dir_name in dirs:
        if dir_name == 'fastq_pass':
            fastq_pass = os.path.join(root, 'fastq_pass')
            break
if fastq_pass:
    source = fastq_pass
else:
    print(f"fastq_pass sub-folder not found in {source}.")
    logger(log, f"fastq_pass sub-folder not found in {source}.")
    sys.exit(1)

header_info = pipeheader(date, tech_name, hostname, ip_address, run_name, sample_list, source, outDir, cpus)

header = header_info[0]
run_info = header_info[1]
for line in header:
    simple_print(line)
    logger(log, line, mode="simple")
for line in run_info:
    simple_print(line)
    logger(log, line, mode="simple")

# Compute pool size (number of parallel samples)
print(f"\nRunig QC on samples in run {run_name}.\n")
logger(log, f"Runig QC on samples in run {run_name}.\n", mode="simple")
print(f"  --> Total CPUs available: {cpus}")
logger(log, f"  --> Total CPUs available: {cpus}", mode="simple")
print(f"  --> Total memory available: {int(a_mem)} GB out of {int(t_mem)} GB.")
logger(log, f"  --> Total memory available: {int(a_mem)} GB out of {int(t_mem)} GB.", mode="simple")
print(f"  --> Using {pool_size} parallel samples, each using {cpus_per_sample} CPU(s).\n")
logger(log, f"  --> Using {pool_size} parallel samples, each using {cpus_per_sample} CPU(s).", mode="simple")

qc_out = os.path.join(outDir, "qc_out")
if not os.path.exists(qc_out):
    os.makedirs(qc_out)

# Ensure that the sample list if formatted correctly
if not os.path.exists(sample_list):
    print(f"Sample list file {sample_list} does not exist.")
    logger(log, f"Sample list file {sample_list} does not exist.")
    sys.exit(1)
else:
    with open(sample_list, 'r') as sampL:
        first_line = sampL.readline().strip().split('\t')
        if len(first_line) != 3:
            print("Sample list file must have three columns: sample, organism, barcode.")
            logger(log, "Sample list file must have three columns: sample, organism, barcode.")
            sys.exit(1)
# Copy the sample sheet to the output directory for reference
sample_sheet_out = os.path.join(outDir, f"{run_name}_sample_sheet.tsv")
with open(sample_list, 'r') as sampL, open(sample_sheet_out, 'w') as outL:
    for line in sampL:
        outL.write(line)

# Load pathogenic bacteria information
bacteria = {}
org_list = files('bactipipe.data').joinpath('pathogenic_bacteria.txt')

with open(org_list, 'r') as orgL:
    for line in orgL:
        parts = line.strip().split('\t')
        if len(parts) >= 2:
            name, size = parts[-1], parts[1]
            bacteria[name] = int(size)

# Validate the sample sheet
bad_organisms = []
bad_samples = []
bad_barcodes = []
with open(sample_list, 'r') as sampL:
    for line in sampL:
        sample, organism, barcode = line.strip().split('\t')
        if organism.strip() not in bacteria and organism not in [ "Lambda", "organism"]:
            print(f"Organism for sample {sample} is not a valid organism name")
            bad_organisms.append(f"{sample}:{organism}")
        if sample != "sample_ID":
            if not sample in os.listdir(source) and barcode.replace("NB", "barcode") not in os.listdir(source):
                print(f"WARNING: Sample {sample} does not have corresponding fastq files.")
                bad_samples.append(sample)
            if "NB" not in barcode and "barcode" not in barcode:
                print(f"Barcode for sample {sample} is not in the correct format.")
                bad_barcodes.append(f"{sample}:{barcode}")
            elif "NB" in barcode and len(barcode) != 4:
                print(f"Barcode for sample {sample} is not in the correct format.")
                bad_barcodes.append(f"{sample}:{barcode}")
            elif "barcode" in barcode and len(barcode) != 9:
                print(f"Barcode for sample {sample} is not in the correct format.")
                bad_barcodes.append(f"{sample}:{barcode}")

if bad_organisms or bad_barcodes:
    print("The sample sheet is not formatted correctly. Please correct the following issues:")
    logger(log, "The sample sheet is not formatted correctly. Please correct the following issues:")
    if bad_organisms:
        print(f"Invalid organisms: {', '.join(bad_organisms)}")
        logger(log, f" --> Invalid organisms: {', '.join(bad_organisms)}", mode="simple")
    if bad_barcodes:
        print(f"Invalid barcodes: {', '.join(bad_barcodes)}")
        logger(log, f" --> Invalid barcodes: {', '.join(bad_barcodes)}", mode="simple")
    sys.exit(1)

start_time = time.time()
logger(log, "PIPELINE STARTED", "Header")
time_print("PIPELINE STARTED", "Header")

if bad_samples:
    b_s = ", ".join(bad_samples)
    time_print(f"WARNING: These samples don't have corresponding fastq data. They will be skipped: {b_s}.", "Fail")
    logger(log, f"WARNING: These samples don't have corresponding fastq data. They will be skipped: {b_s}.")

sample_number = sum(1 for line in open(sample_list) if not line.startswith("sample_ID")) - len(bad_samples)


qc_start_msg = "Performing Quality Control"
time_print(qc_start_msg, "Header")
logger(log, qc_start_msg, "Header")

time_print(f"\nTotal number of samples to be processed: {sample_number}\n")
print()
logger(log, f"Total number of samples to be processed: {sample_number}\n")

# Read sample list and process in parallel
with open(sample_list, 'r') as sampL:
    sample_lines = sampL.readlines()[1:] # Skip the header row

# process_map(process_sample, sample_lines, max_workers=pool_size)
q_bar_fmt = '{l_bar} {bar:40} {n_fmt}/{total_fmt} [{elapsed}{postfix}]'

process_map(
	process_sample,
	sample_lines,
	max_workers=pool_size,
    bar_format=q_bar_fmt,
	desc="---> Processing fastq files: ",
	colour ='yellow',
)

# Count the number of samples that passed QC
passed_samples = [sample for sample in os.listdir(qc_out) if os.path.exists(os.path.join(qc_out, sample, "quality_metrics_after_qc.txt"))]

passed_number = len(passed_samples)
pass_msg = f"Quality control successful for {passed_number} of {sample_number} samples."
print()
time_print(pass_msg, "Pass")
logger(log, pass_msg)

# Print samples that failed QC
failed_samples = [sample for sample in os.listdir(qc_out) if not os.path.exists(os.path.join(qc_out, sample, f"{sample}.fastq.gz") and sample != "temp_qc_summary.tsv")]

if failed_samples:
    print()
    failures = ".".join(failed_samples)
    fail_msg = f'QC failed for samples: {failures}.'
    time_print(fail_msg, "Fail")
    logger(log, fail_msg)

# Assemble genomes for samples that passed QC
assembly_start_msg = "Genome Assembly for samples that passed QC" 
time_print(assembly_start_msg, "Header")
logger(log, assembly_start_msg, "Header")

fastq_files = [os.path.join(qc_out, sample, f"{sample}.fastq.gz") for sample in os.listdir(qc_out) if os.path.exists(os.path.join(qc_out, sample, f"{sample}.fastq.gz"))]

genomes_dir = os.path.join(outDir, "assemblies", "genomes")
if not os.path.exists(genomes_dir):
    os.makedirs(genomes_dir)

existing_genomes = [f.split(".")[0] for f in os.listdir(genomes_dir) if f.endswith(".fasta") and os.path.getsize(os.path.join(genomes_dir, f)) > 0]

if len(existing_genomes) == 0:
    num_to_assemble = passed_number
    assembly_input = [[sample, fastq] for sample in os.listdir(qc_out) 
                      for fastq in fastq_files 
                      if os.path.basename(fastq).startswith(sample)]

    print(f"  ---> Genomes for {passed_number} samples will be assembled.")
    logger(log, f"  ---> Genomes for {passed_number} samples will be assembled.", mode="simple")
    
elif len(existing_genomes) > 0 and len(existing_genomes) < passed_number:
    num_to_assemble = passed_number - len(existing_genomes)
    assembly_input = [[sample, fastq] for sample in os.listdir(qc_out) 
                      for fastq in fastq_files 
                      if os.path.basename(fastq).startswith(sample)]
    time_print(f"Genomes for {len(existing_genomes)} samples have been assembled already.")
    logger(log, f"Genomes for {len(existing_genomes)} samples have been assembled already.")
    simple_print(f"---> Genomes for {num_to_assemble} samples will be assembled.")
    logger(log, f"---> Genomes for {num_to_assemble} samples will be assembled.", mode="simple")

elif len(existing_genomes) == passed_number:
    num_to_assemble = 0
    assembly_input = []
    time_print("Genomes for all samples have been assembled already. Skiping assembly!")
    logger(log, "Genomes for all samples have been assembled already. Skiping assembly!")

if assembly_input:
    if num_to_assemble < pool_size:
        cpus_per_sample = max(1, cpus // num_to_assemble)

    simple_print(f"  ---> {cpus_per_sample} CPUs will be used per sample.")
    logger(log, f"  ---> {cpus_per_sample} CPUs will be used per sample.", mode="simple")
    print()

    a_bar_fmt = '{l_bar} {bar:40} {n_fmt}/{total_fmt} [{elapsed}{postfix}]'
    process_map(
        assemble_sample,
        assembly_input,
        max_workers=pool_size,
        bar_format=a_bar_fmt,
        desc="---> Assembling genomes: ",
        colour ='yellow',
    )

# Count the number of samples that have been assembled
assembled_samples = [f for f in os.listdir(genomes_dir) if f.endswith(".fasta") and os.path.getsize(os.path.join(genomes_dir, f)) > 0]

assembled_number = len(assembled_samples)
assembly_msg = f"Genome assembly completed for {assembled_number} of {passed_number} samples.\n"
print()
time_print(assembly_msg, "Pass")
logger(log, assembly_msg, "Pass")

# Print samples that failed assembly
failed_assembly = [sample for sample in passed_samples if not os.path.exists(os.path.join(genomes_dir, f"{sample}.fasta")) or os.path.getsize(os.path.join(genomes_dir, f"{sample}.fasta")) == 0]
if failed_assembly:
    failed_assembly_msg = f'Assembly failed for samples: {", ".join(failed_assembly)}.\n'
    time_print(failed_assembly_msg, "Fail")
    logger(log, failed_assembly_msg, "Fail")

kmer_message = "Verifying Taxonomic Identity"
time_print(kmer_message, "Header")
logger(log, kmer_message, "Header")

# Find the organism for each sample
temp_qc_summary = os.path.join(qc_out, "temp_qc_summary.tsv")
with(open(temp_qc_summary , 'w')) as qc_sum:
    writer = csv.writer(qc_sum, dialect='excel-tab')
    writer.writerow(["Sample",  "Mean_quality", "qc_verdict", "Expected organism", "Identified organism", "% Match", "Coverage", "cov_verdict", "tax_confirm"])
    with open(sample_list, 'r') as sampL:
        for line in sampL:
            sample, organism, barcode = line.strip().split('\t')
            if sample == "sample_ID":
                continue
            genome = os.path.join(outDir, "assemblies", "genomes", f"{sample}.fasta")
            # Find quality metrics:
            qc_metrics_after = os.path.join(qc_out, sample, "quality_metrics_after_qc.txt")
            qc_metrics_raw = os.path.join(qc_out, sample, "raw_reads_quality_metrics.txt")
            if os.path.exists(qc_metrics_after):
                qc_verdict = "Pass"
                qc_file = qc_metrics_after
            else:
                qc_verdict = "Fail"
                qc_file = qc_metrics_raw
            with open(qc_file, 'r') as qcF:
                lines = qcF.readlines()
            
            total_bases = int(float(next(line for line in lines if "Total bases:" in line).split(":")[1].strip().replace(",", "")))
            avqc = float(next(line for line in lines if "Mean read quality:" in line).split(":")[1].strip())
            genome_size = 48502 if organism == "Lambda" else bacteria.get(organism, None)
            coverage = total_bases/genome_size
            if coverage >= mincov:
                cov_verdict = "Pass"
            else:
                cov_verdict = "Fail"

            # Find organism 
            hit, tax_confirm, possibilities = find_orgnanism.find_species_with_kmrf(s_name=sample, lab_species=organism, genome=genome, dataOut=outDir, org_type="bacteria", logfile=log)

            if qc_verdict == "Pass" and cov_verdict == "Pass":
                #######
                if tax_confirm == "Pass":
                    best_org = hit.split(" (")[0]
                    best_percent = hit.split(" (")[1].strip(")")
                    writer.writerow([sample, f'{avqc:.2f}', qc_verdict, organism, best_org, best_percent, f'{coverage:.2f}', cov_verdict, tax_confirm])
                else:
                    best_other_hit = hit.split(" --- ")[0].split(": ")[1]
                    best_other_org = best_other_hit.split(" (")[0]
                    best_other_percent = best_other_hit.split(" (")[1].strip(")")
                    writer.writerow([sample, f'{avqc:.2f}', qc_verdict, organism, f'Closest: {best_other_org}', best_other_percent, f'{coverage:.2f}', cov_verdict, tax_confirm])
            else:
                best_org = "N/A"
                best_percent = "N/A"
                tax_confirm = "N/A"

                writer.writerow([sample, f'{avqc:.2f}', qc_verdict, organism, best_org, best_percent, f'{coverage:.2f}', cov_verdict, tax_confirm])                    

# Assess Genome Quality with CheckM
genomes_dir = os.path.join(outDir, "assemblies", "genomes")
checkm_dir = os.path.join(outDir, "checkM")
checkm_out = process_data.checkM_stats(genomes_dir=genomes_dir, cpus=cpus, outdir=checkm_dir, logfile=log)

# Final summary
qc_summary = os.path.join(outDir, f"{run_name}_qc_summary.tsv")
time_print('Final summary', "Header")
logger(log, 'Final summary', "Header")

process_data.make_summary(qc_summary=qc_summary, temp_qc_summary=temp_qc_summary, header=header, checkm_out=checkm_out, logfile=log)

# Delete fastq samples from the QC step
if args.clean:
    for sample in os.listdir(qc_out):
        sample_dir = os.path.join(qc_out, sample)
        if os.path.isdir(sample_dir):
            for file in os.listdir(sample_dir):
                gonome_file = os.path.join(genomes_dir, f"{sample}.fasta")
                if file.endswith(".fastq.gz") and os.path.exists(gonome_file) and os.path.getsize(gonome_file) > 0:
                    os.remove(os.path.join(sample_dir, file))
    clean_msg = "Fastq files generated during QC step have been deleted to save space."
    time_print(clean_msg)
    logger(log, clean_msg)
    
# End the timer
end_time = time.time()

# Calculate elapsed time
elapsed_time = end_time - start_time
hours, remainder = divmod(elapsed_time, 3600)
minutes, seconds = divmod(remainder, 60)

# Print the execution time
end_message = f"PIPELINE COMPLETED: Processed {sample_number} samples in {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds"
time_print(end_message, "Header")
logger(log, end_message, "Header")
print("\n")
