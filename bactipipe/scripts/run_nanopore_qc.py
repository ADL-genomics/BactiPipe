import sys
import os
import csv
import time
import psutil
import shutil
import socket
import nano_qc
import argparse
import subprocess
from datetime import datetime
from bactipipe.scripts import process_data
from bactipipe.scripts import find_organism
from importlib.resources import files as resource_files
from bactipipe.scripts.utils import compress_qc_fastqs, logger, pipeheader, excel_reader, time_print, simple_print
from tqdm.contrib.concurrent import process_map


class CustomHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):
    def __init__(self, *args, **kwargs):
        kwargs['width'] = 100  # Set the width of the help message
        super().__init__(*args, **kwargs)

    def _get_help_string(self, action):
        if action.default is not None and action.default != argparse.SUPPRESS:
            return super()._get_help_string(action)
        return action.help

parser = argparse.ArgumentParser(
    description="Perform quality control on nanopore reads, assemble genomes for reads that pass QC, and check quality for assembled genomes.",
    formatter_class=CustomHelpFormatter,
    add_help=False  # Disable default help to add it manually
)

required_args = parser.add_argument_group('Required arguments')
optional_args = parser.add_argument_group('Optional arguments')


required_args.add_argument("-n", "--name",
                    help='Name of the person running the pipeline. Needs quotations to handle spaces.\
                        Example: -n "Jane Doe"', required=True)

required_args.add_argument("-r", "--run_name",
                    help="Run name (Run ID)", required=True)

required_args.add_argument("-l", "--sample_sheet",
                    help="A three-column file with sample (column 1), organism species (column2), barcode(column3 -- [format: NBDXX or barcodeXX]).", required=True)

required_args.add_argument('-s', '--source', help='The source directory.', required=True)

optional_args.add_argument("-o", "--outdir",
                    help="Path to output directory. Default: current directory.")
optional_args.add_argument('-t', '--threads', help='Number of CPUs per sample. Default: all available.', type=int)


optional_args.add_argument("--cpus_per_sample", help="Number of CPUs per sample. Must be lower than total allocated CPUs. If not provided,  it will be calculated based on available resources.", type=int)

optional_args.add_argument("-m", "--mincov", help="Minimum genome coverage depth.", default=50, type=int)
optional_args.add_argument("-q", "--minqual", help="Average read quality threshold.", default=15, type=int)
optional_args.add_argument ("-a", "--assembler", help="Genome assembler to use. Default: Unicycler",  choices=["Flye", "Unicycler"], default="Flye")

optional_args.add_argument("--use-s3", help="Use S3 for input. Default: False", action="store_true")

optional_args.add_argument("--bucket", help="S3 bucket name. Required if --use-s3 is set.", type=str, default=None)

optional_args.add_argument("--clean",
                            help="This will delete all fastq samples generated by QC step.",
                            action="store_true")

optional_args.add_argument("-h", "--help",
                           action="help",
                           help="Show this help message and exit.")

args = parser.parse_args()

    # Function to run quality control for a single sample
def process_sample(line):

    sample, organism, barcode = line.strip().split('\t')
    barcode = barcode.replace("NB", "barcode")
    # Determine genome size as a float, raising an error if unknown
    if organism == "Lambda":
        genome_size = 48502
    else:
        size = bacteria.get(organism, 5e6) # Placeholder for unknown organisms/ Recalculate after assembly
        if size is None:
            raise ValueError(f"Unknown organism: {organism}")
        genome_size = int(size)
    raw_folder = os.path.join(source, barcode)
    output_fastq = f"{sample}.fastq"
    output_dir = os.path.join(qc_out, sample)

    # Run QC with controlled CPU allocation
    if not sample.startswith("#"):
        nano_qc.qc_nano(
            raw_folder=raw_folder,
            genome_size=genome_size,
            min_avg_quality=minqual,
            min_coverage=mincov,
            desired_coverage=300,
            output_fastq=output_fastq,
            output_dir=output_dir,
            cpus=str(cpus_per_sample),
            s3=args.use_s3,
            bucket=args.bucket if args.use_s3 else None,
            logfile=os.path.join(output_dir, f"{sample}_qc_nano.log")
        )

# Function for genome assembly for one sample
if args.assembler:
    assembler = args.assembler.strip().lower()
else:
    assembler = "flye"
def assemble_sample(assembly_input):
    sample = assembly_input[0]
    fastq = assembly_input[1]
    genome_size = 48502 if organism == "Lambda" else bacteria.get(organism, None)
    # Assemble the genomes of the samples that passed the quality control
    assembly_dir = os.path.join(outDir, "assemblies")
    genome = os.path.join(assembly_dir, "genomes", f"{sample}.fasta")
    if os.path.exists(genome):
        return
    process_data.assemble(sample=sample, reads=[fastq], assembly_dir=assembly_dir, assembler=assembler, sequencer="nanopore", cpus=cpus_per_sample, gsize = genome_size, single=False) # type: ignore
    return

# Run the pipeline
tech_name = args.name
run_name = args.run_name
source = args.source
source = os.path.join(source, run_name)
mincov = args.mincov
minqual = args.minqual
if args.outdir:
    outDir = os.path.join(args.outdir, run_name)
else:
    outDir = os.path.join(os.getcwd(), run_name)


sample_list = os.path.abspath(args.sample_sheet)

log_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
log = os.path.join(outDir, f"{log_time}~{run_name}_qc.log")

date = datetime.now().strftime("%Y-%m-%d")
hostname = socket.gethostname()
def new_func(s):
    s.connect(('10.254.254.254', 1))

try:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        # doesn't even have to be reachable
        new_func(s)
        ip_address = s.getsockname()[0]
    except Exception as e:
        logger(log, f"Unable to resolve hostname: {e}")
        time_print(f"Unable to resolve hostname: {e}", "Fail")
        ip_address = "Not detected"
    finally:
        s.close()
except Exception as e:
    ip_address = f"Unable to resolve hostname: {e}"
    ip_address = "Unable to resolve hostname"

# Manage computational resources
if args.threads:
    cpus = args.threads
else:
    cpus = os.cpu_count()


opt_cpus = max(1, cpus // 8)  # type: ignore # Optimal number of CPUs per sample
if opt_cpus == 1:
    defaut_max_samps = 1 # We can only run one sample at a time
else:
    defaut_max_samps = cpus // opt_cpus  # Maximum number of samples to process in parallel

# Calculate available memory
mem = psutil.virtual_memory()
a_mem = mem.available / 1024**3  # available memory in GB
t_mem = mem.total / 1024**3  # total memory in GB
 
allowed_samps = a_mem // 8  # 8 GB per sample

if allowed_samps < 1:
    logger(log, "Insufficient memory available to run the pipeline.")
    time_print("Insufficient memory available to run the pipeline.", "Fail")
    sys.exit(1)

if allowed_samps < defaut_max_samps:
    pool_size = allowed_samps
else:
    pool_size = defaut_max_samps

if args.cpus_per_sample:
    cpus_per_sample = args.cpus_per_sample
else:
    cpus_per_sample = max(1, cpus // pool_size) # type: ignore

# Ensure that the source directory exists
if not os.path.exists(source):
    # print(f"Source directory {source} does not exist.")
    logger(log, f"Source directory {source} does not exist.")
    time_print(f"Source directory {source} does not exist.", "Fail")
    sys.exit(1)

fastq_pass = None
for root, dirs, files in os.walk(source):
    for dir_name in dirs:
        if dir_name == 'fastq_pass':
            fastq_pass = os.path.join(root, 'fastq_pass')
            break
    if fastq_pass:
        break

if fastq_pass:
    source = fastq_pass
else:
    logger(log, f"fastq_pass sub-folder not found in {source}.")
    time_print(f"fastq_pass sub-folder not found in {source}.", "Fail")
    sys.exit(1)

header_info = pipeheader(date, tech_name, hostname, ip_address, run_name, sample_list, source, outDir, cpus)

header = header_info[0]
run_info = header_info[1]
for line in header:
    simple_print(line)
    logger(log, line, mode="simple")
for line in run_info:
    simple_print(line)
    logger(log, line, mode="simple")

qc_out = os.path.join(outDir, "qc_out")
if not os.path.exists(qc_out):
    os.makedirs(qc_out)


# Ensure that the sample list if formatted correctly
if not os.path.exists(sample_list):
    # print(f"Sample list file {sample_list} does not exist.")
    logger(log, f"Sample list file {sample_list} does not exist.")
    time_print(f"Sample list file {sample_list} does not exist.", "Fail")
    sys.exit(1)
else:
    if sample_list.endswith('.xlsx') or sample_list.endswith('.xls'):
        # If the sample list is an Excel file, read it
        try:
            sample_info = excel_reader(sample_list)
        except Exception as e:
            logger(log, f"Error reading Excel file {sample_list}: {e}")
            time_print(f"Error reading Excel file {sample_list}: {e}", "Fail")
            sys.exit(1)
    else:
        with open(sample_list, 'r') as sampL:
            sample_info = sampL.readlines()

        first_line = sample_info[0].strip().split('\t')
        if len(first_line) != 3:
            logger(log, "Sample list file must have three columns: sample, organism, barcode.")
            time_print("Sample list file must have three columns: sample, organism, barcode.", "Fail")
            sys.exit(1)

# Load pathogenPlease coic bacteria information
bacteria = {}
org_list = resource_files('bactipipe.data').joinpath('pathogenic_bacteria.txt')

with open(org_list, 'r') as orgL:
    for line in orgL:
        parts = line.strip().split('\t')
        if len(parts) >= 2:
            name, size = parts[-1], parts[1]
            bacteria[name] = int(size)

# Validate the sample sheet
bad_organisms = []
bad_samples = []
bad_barcodes = []


# with open(sample_list, 'r') as sampL:
for line in sample_info:
    if line.startswith("#"):
        continue
    sample, organism, barcode = line.strip().split('\t')
    if organism.strip() not in bacteria and organism.lower() not in [ "lambda", "organism", "unknown"]:
        logger(log, f"WARNING: Organism [{organism.strip()}] for sample {sample} is not a valid organism name")
        time_print(f"WARNING: Organism [{organism.strip()}] for sample {sample} is not a valid organism name")
        bad_organisms.append(f"{sample}:{organism}")
    
    if not sample in os.listdir(source) and barcode.replace("NB", "barcode") not in os.listdir(source):
        logger(log, f"WARNING: Sample {sample} does not have corresponding fastq files.")
        time_print(f"WARNING: Sample {sample} does not have corresponding fastq files.", "Fail")
        bad_samples.append(sample)
    if "NB" not in barcode and "barcode" not in barcode:
        logger(log, f"Barcode for sample {sample} is not in the correct format.")
        time_print(f"Barcode for sample {sample} is not in the correct format.", "Fail")
        bad_barcodes.append(f"{sample}:{barcode}")
    elif "NB" in barcode and len(barcode) != 4:
        logger(log, f"Barcode for sample {sample} is not in the correct format.")
        time_print(f"Barcode for sample {sample} is not in the correct format.", "Fail")
        bad_barcodes.append(f"{sample}:{barcode}")
    elif "barcode" in barcode and len(barcode) != 9:
        logger(log, f"Barcode for sample {sample} is not in the correct format.")
        time_print(f"Barcode for sample {sample} is not in the correct format.", "Fail")
        bad_barcodes.append(f"{sample}:{barcode}")

if bad_barcodes:
    logger(log, "The sample sheet is not formatted correctly. Please correct the following issues:")
    time_print("The sample sheet is not formatted correctly. rrect the following issues:", "Fail")
    logger(log, f" --> Invalid barcodes: {', '.join(bad_barcodes)}")
    time_print(f" --> Invalid barcodes: {', '.join(bad_barcodes)}")
    sys.exit(1)

if bad_organisms:
    time_print("WARNING: Invalid organism names may cause QC failures.", "Fail")
    logger(log, "WARNING: Invalid organism names may cause QC failures.")

if bad_samples:
    b_s = ", ".join(bad_samples)
    time_print(f"WARNING: These samples don't have corresponding fastq data. They will be skipped: {b_s}.", "Fail")
    logger(log, f"WARNING: These samples don't have corresponding fastq data. They will be skipped: {b_s}.")

sample_number = sum(1 for line in sample_info if not line.startswith("#")) - len(bad_samples)


if pool_size > sample_number:
    pool_size = sample_number
    # Recalculate CPUs per sample
    cpus_per_sample = max(1, cpus // pool_size)

# Compute pool size (number of parallel samples)
print(f"\nRunig QC on samples in run {run_name}.\n")
logger(log, f"Running QC on samples in run {run_name}.\n")
print(f"  --> Total CPUs available: {cpus}")
logger(log, f"  --> Total CPUs available: {cpus}")
print(f"  --> Total memory available: {int(a_mem)} GB out of {int(t_mem)} GB.")
logger(log, f"  --> Total memory available: {int(a_mem)} GB out of {int(t_mem)} GB.")
print(f"  --> Using {pool_size} parallel samples, each using {cpus_per_sample} CPU(s).\n")
logger(log, f"  --> Using {pool_size} parallel samples, each using {cpus_per_sample} CPU(s).")


start_time = time.time()
logger(log, "PIPELINE STARTED", "Header")
time_print("PIPELINE STARTED", "Header")


qc_start_msg = "Performing Quality Control"
time_print(qc_start_msg, "Header")
logger(log, qc_start_msg, "Header")

time_print(f"\nTotal number of samples to be processed: {sample_number}\n")
print()
logger(log, f"Total number of samples to be processed: {sample_number}\n")


# Read sample list and process in parallel
# with open(sample_list, 'r') as sampL:
# lines = 
if sample_info[0].startswith('#'):
    sample_lines = [line.strip() for line in sample_info[1:]]
else:
    sample_lines = sample_info

# QC stage (multiprocessing) ----
q_bar_fmt = '{l_bar} {bar:40} {n_fmt}/{total_fmt} [{elapsed}{postfix}]'
process_map(
    process_sample,
    sample_lines,
    max_workers=pool_size,
    bar_format=q_bar_fmt,
    chunksize=1,
    desc="---> Processing fastq files: ",
    colour="yellow",
    disable=False,
)

# Count the number of samples that passed QC
passed_samples = [sample for sample in os.listdir(qc_out) if os.path.exists(os.path.join(qc_out, sample, sample + ".fastq")) and os.path.exists(os.path.join(qc_out, sample, "quality_metrics.txt"))]

passed_number = len(passed_samples)
pass_msg = f"Available for assembly: {passed_number} of {sample_number} samples."
print()
time_print(pass_msg, "Pass")
logger(log, pass_msg)

if len(passed_samples) == 0:
    time_print("No samples passed QC. Exiting pipeline.", "Fail")
    logger(log, "No samples passed QC. Exiting pipeline.")
    sys.exit(1)

# Print samples that failed QC
failed_samples = [sample for sample in os.listdir(qc_out) if not os.path.exists(os.path.join(qc_out, sample, f"{sample}.fastq")) and sample != "temp_qc_summary.tsv"]

if failed_samples:
    print()
    failures = ".".join(failed_samples)
    fail_msg = f'QC failed for samples: {failures}.'
    time_print(fail_msg, "Fail")
    logger(log, fail_msg)

# Assemble genomes for samples that passed QC
assembly_start_msg = "Genome Assembly for samples that passed QC" 
time_print(assembly_start_msg, "Header")
logger(log, assembly_start_msg, "Header")

fastq_files = [os.path.join(qc_out, sample, f"{sample}.fastq") for sample in os.listdir(qc_out) if os.path.exists(os.path.join(qc_out, sample, f"{sample}.fastq"))]

genomes_dir = os.path.join(outDir, "assemblies", "genomes")
if not os.path.exists(genomes_dir):
    os.makedirs(genomes_dir)

existing_genomes = [f.split(".")[0] for f in os.listdir(genomes_dir) if f.endswith(".fasta") and os.path.getsize(os.path.join(genomes_dir, f)) > 0]

if len(existing_genomes) == 0:
    num_to_assemble = passed_number
    assembly_input = [[sample, fastq] for sample in os.listdir(qc_out) 
                      for fastq in fastq_files 
                      if os.path.basename(fastq).startswith(sample)]

    print(f"  ---> Genomes for {passed_number} samples will be assembled.")
    logger(log, f"  ---> Genomes for {passed_number} samples will be assembled.")

elif len(existing_genomes) > 0 and len(existing_genomes) < passed_number:
    num_to_assemble = passed_number - len(existing_genomes)
    assembly_input = [[sample, fastq] for sample in os.listdir(qc_out) 
                      for fastq in fastq_files 
                      if os.path.basename(fastq).startswith(sample)]
    time_print(f"Genomes for {len(existing_genomes)} samples have been assembled already.")
    logger(log, f"Genomes for {len(existing_genomes)} samples have been assembled already.")

    simple_print(f"---> Genomes for {num_to_assemble} samples will be assembled.")
    logger(log, f"---> Genomes for {num_to_assemble} samples will be assembled.")

elif len(existing_genomes) == passed_number:
    num_to_assemble = 0
    assembly_input = []
    time_print("Genomes for all samples have been assembled already. Skiping assembly!")
    logger(log, "Genomes for all samples have been assembled already. Skiping assembly!")

if assembly_input:
    if num_to_assemble < pool_size:
        cpus_per_sample = max(1, cpus // num_to_assemble)
    
    if assembler == "unicycler":
        cpus_per_sample = max(cpus_per_sample, 10)
        pool_size = cpus // cpus_per_sample

    vercmd = f'{assembler} --version'
    stdout = subprocess.run(vercmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    out = stdout.stdout.decode('utf-8')
    version = out.split()[-1]

    assember_message = f"Using {assembler.capitalize()} (version: {version})."

    simple_print(f"  ---> {assember_message}")
    logger(log, f"  ---> {assember_message}")

    simple_print(f"  ---> {cpus_per_sample} CPUs will be used per sample.")
    logger(log, f"  ---> {cpus_per_sample} CPUs will be used per sample.")

    a_bar_fmt = '{l_bar} {bar:40} {n_fmt}/{total_fmt} [{elapsed}{postfix}]'
    process_map(
        assemble_sample,
        assembly_input,
        max_workers=pool_size,
        bar_format=a_bar_fmt,
        chunksize=1,
        desc="---> Assembling genomes: ",
        colour="green",
        disable=False,
    )

# Count the number of samples that have been assembled
assembled_samples = [f for f in os.listdir(genomes_dir) if f.endswith(".fasta") and os.path.getsize(os.path.join(genomes_dir, f)) > 0]

assembled_number = len(assembled_samples)
assembly_msg = f"Genome assembly completed for {assembled_number} of {passed_number} samples.\n"
print()
time_print(assembly_msg, "Pass")
logger(log, assembly_msg)

# Print samples that failed assembly
failed_assembly = [sample for sample in passed_samples if not os.path.exists(os.path.join(genomes_dir, f"{sample}.fasta")) or os.path.getsize(os.path.join(genomes_dir, f"{sample}.fasta")) == 0]
if failed_assembly:
    failed_assembly_msg = f'Assembly failed for samples: {", ".join(failed_assembly)}.\n'
    time_print(failed_assembly_msg, "Fail")
    logger(log, failed_assembly_msg, "Fail")

if len(failed_assembly) == passed_number:
    time_print("No samples were assembled. Exiting pipeline.", "Fail")
    logger(log, "No samples were assembled. Exiting pipeline.")
    sys.exit(1)

kmer_message = "Verifying Taxonomic Identity"
time_print(kmer_message, "Header")
logger(log, kmer_message, "Header")

# Find the organism for each sample
temp_qc_summary = os.path.join(qc_out, "temp_qc_summary.tsv")
with(open(temp_qc_summary , 'w')) as qc_sum:
    writer = csv.writer(qc_sum, dialect='excel-tab')
    writer.writerow(["Sample",  "Mean_quality", "qc_verdict", "Expected organism", "Identified organism", "% Match", "Coverage", "min_cov", "cov_verdict", "tax_confirm"])

    for line in sample_info:
        if line.startswith("#"):
            continue
        sample, organism, barcode = line.strip().split('\t')

        if organism not in bacteria:
            sys_organism = "unknown"
            genome_size = None
        else:
            sys_organism = organism
            genome_size = 48502 if organism == "Lambda" else bacteria.get(organism, None)  

        genome = os.path.join(outDir, "assemblies", "genomes", f"{sample}.fasta")
        if not os.path.exists(genome) or os.path.getsize(genome) == 0:
            time_print(f"WARNING: Sample {sample} does not have a valid genome file. Skipping.", "Fail")
            logger(log, f"WARNING: Sample {sample} does not have a valid genome file. Skipping.")
            continue
        # Find quality metrics:
        qc_file = os.path.join(qc_out, sample, "quality_metrics.txt")

        with open(qc_file, 'r') as qcF:
            lines = qcF.readlines()
        
        # Extract total bases
        bases_line = next((l for l in lines if "Total bases:" in l), None)
        if bases_line is None:
            bases_line = next((l for l in lines if "Raw Total Bases:" in l), None)
        if bases_line is None:
            logger(log, f"Total bases line not found in QC metrics for sample {sample}")
            continue
        total_bases = int(float(bases_line.split(":")[1].strip().replace(",", "")))

        # Extract mean read quality
        qual_line = next((l for l in lines if "Trimmed Mean Read Quality:" in l), None)
        if qual_line is None:
            qual_line = next((l for l in lines if "Raw Mean Read Quality:" in l), None)
        if qual_line is None:
            logger(log, f"Mean read quality line not found in QC metrics for sample {sample}")
            continue
        total_bases = int(float(bases_line.split(":")[1].strip().replace(",", "")))
        avqc = float(qual_line.split(":")[1].strip())

        if avqc < minqual:
            qc_verdict = "Fail"
        else:
            qc_verdict = "Pass"

        if genome_size:
            coverage = total_bases/genome_size
            cov_display = f"{coverage:.2f}"
            if coverage >= mincov:
                cov_verdict = "Pass"
            else:
                cov_verdict = "Fail"
        else:
            coverage = "N/A"
            cov_verdict = "N/A"
            cov_display = "N/A"

        # Find organism 
        hit, tax_confirm, possibilities = find_organism.find_species_with_kmrf(s_name=sample, lab_species=sys_organism, genome=genome, dataOut=outDir, org_type="bacteria", logfile=log)

        best_org = None
        best_percent = None
        best_other_org = None
        if tax_confirm == "Pass" or tax_confirm == "N/A":
            best_org = hit.split(" (")[0]
            best_percent = hit.split(" (")[1].strip(")")
        else:
            best_other_hit = hit.split(" --- ")[0].split(": ")[1]
            best_other_org = best_other_hit.split(" (")[0]
            best_other_percent = best_other_hit.split(" (")[1].strip(")")

        # Update coverage for samples with pre-unknown organisms
        if coverage == "N/A" and organism != "unknown":
            if best_org:
                identified_org = best_org
            elif best_other_org:
                identified_org = best_other_org
            if identified_org in bacteria:
                g_size = bacteria.get(identified_org, None)[0]
                coverage = total_bases / int(g_size)
                cov_display = f"{coverage:.2f}X"

        if best_org:
            writer.writerow([sample, f'{avqc:.2f}', qc_verdict, organism, best_org, best_percent, cov_display, mincov, cov_verdict, tax_confirm])
        else:
            writer.writerow([sample, f'{avqc:.2f}', qc_verdict, organism, f'Closest: {best_other_org}', best_other_percent, cov_display, mincov, cov_verdict, tax_confirm])

# Assess Genome Quality with CheckM
genomes_dir = os.path.join(outDir, "assemblies", "genomes")
checkm_dir = os.path.join(outDir, "checkM")
checkm_out = process_data.checkM_stats(genomes_dir=genomes_dir, cpus=cpus, outdir=checkm_dir, logfile=log)

# Final summary
qc_summary = os.path.join(outDir, f"{run_name}_qc_summary.tsv")
time_print('Final summary', "Header")
logger(log, 'Final summary', "Header")

process_data.make_summary(qc_summary=qc_summary, temp_qc_summary=temp_qc_summary, header=header, checkm_out=checkm_out, logfile=log)

# Delete fastq samples from the QC step
if args.clean:
    for sample in os.listdir(qc_out):
        sample_dir = os.path.join(qc_out, sample)
        if os.path.isdir(sample_dir):
            for file in os.listdir(sample_dir):
                gonome_file = os.path.join(genomes_dir, f"{sample}.fasta")
                if file.endswith(".fastq") and os.path.exists(gonome_file) and os.path.getsize(gonome_file) > 0:
                    os.remove(os.path.join(sample_dir, file)) 
    time_print("Fastq files generated during QC step have been deleted to save space.", "Pass")
    logger(log, "Fastq files generated during QC step have been deleted to save space.")
else:

    def _parent_log_adapter(message: str, level: str = "Norm"):
        logger(log, message, message_type=level)

    # compress uncompressed FASTQs at the end of the pipeline
    summary = compress_qc_fastqs(
        qc_out=qc_out,
        genomes_dir=genomes_dir,
        cpus_per_sample=int(cpus_per_sample),
        require_assembly=False,
        recursive=False,
        remove_source=True,
        logger_fn=_parent_log_adapter,
    )
    logger(log, f"Compression summary: {summary}")

# End the timer
end_time = time.time()

# Calculate elapsed time
elapsed_time = end_time - start_time
hours, remainder = divmod(elapsed_time, 3600)
minutes, seconds = divmod(remainder, 60)

# Print the execution time
end_message = f"PIPELINE COMPLETED: Processed {sample_number} samples in {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds"
time_print(end_message, "Header")
logger(log, end_message, "Header")
print("\n")

# Cleanly stop the logging listener
try:
    log_listener.stop()
except Exception:
    pass
